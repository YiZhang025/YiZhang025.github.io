---
---
@String(PAMI = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(IJCV = {Int. J. Comput. Vis.})
@String(CVPR= {IEEE Conf. Comput. Vis. Pattern Recog.})
@String(ICCV= {Int. Conf. Comput. Vis.})
@String(ECCV= {Eur. Conf. Comput. Vis.})
@String(NIPS= {Adv. Neural Inform. Process. Syst.})
@String(ICPR = {Int. Conf. Pattern Recog.})
@String(BMVC= {Brit. Mach. Vis. Conf.})
@String(TOG= {ACM Trans. Graph.})
@String(TIP  = {IEEE Trans. Image Process.})
@String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
@String(TMM  = {IEEE Trans. Multimedia})
@String(ACMMM= {ACM Int. Conf. Multimedia})
@String(ICME = {Int. Conf. Multimedia and Expo})
@String(ICASSP=	{ICASSP})
@String(ICIP = {IEEE Int. Conf. Image Process.})
@String(ACCV  = {ACCV})
@String(ICLR = {Int. Conf. Learn. Represent.})
@String(IJCAI = {IJCAI})
@String(PR   = {Pattern Recognition})
@String(AAAI = {AAAI})
@String(CVPRW= {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
@String(CSVT = {IEEE Trans. Circuit Syst. Video Technol.})
@String(TNNLS = {IEEE Trans. Neural Netw. Learn. Syst.})
@String(bioRxiv = {bioRxiv})
@String(STACOM = {STACOM})
@String(MIDL-S = {MIDL-S})

@String(SPL	= {IEEE Sign. Process. Letters})
@String(VR   = {Vis. Res.})
@String(JOV	 = {J. Vis.})
@String(TVC  = {The Vis. Comput.})
@String(JCST  = {J. Comput. Sci. Tech.})
@String(CGF  = {Comput. Graph. Forum})
@String(CVM = {Computational Visual Media})


@String(PAMI  = {IEEE TPAMI})
@String(IJCV  = {IJCV})
@String(CVPR  = {CVPR})
@String(ICCV  = {ICCV})
@String(ECCV  = {ECCV})
@String(NIPS  = {NeurIPS})
@String(ICPR  = {ICPR})
@String(BMVC  =	{BMVC})
@String(TOG   = {ACM TOG})
@String(TIP   = {IEEE TIP})
@String(TVCG  = {IEEE TVCG})
@String(TCSVT = {IEEE TCSVT})
@String(TMM   =	{IEEE TMM})
@String(ACMMM = {ACM MM})
@String(ICME  =	{ICME})
@String(ICASSP=	{ICASSP})
@String(ICIP  = {ICIP})
@String(ACCV  = {ACCV})
@String(ICLR  = {ICLR})
@String(IJCAI = {IJCAI})
@String(PR = {PR})
@String(AAAI = {AAAI})
@String(CVPRW= {CVPRW})
@String(CSVT = {IEEE TCSVT})
@String(TNNLS = {IEEE TNNLS})
@String(bioRxiv = {bioRxiv})
@String(STACOM = {STACOM})
@String(MIDL-S = {MIDL-S})
@String(SCMR-A = {SCMR-A})


@article{zhang2024torcht,
title={Torch{$T_1$}: {GPU}-accelerated cardiac {$T_1$} mapping with deep learning framework},
abbr = {MIDL-S},
author={Yi Zhang and Yidong Zhao and Yifeng Shao and Nuno Miguel Ferreira Capit{\~a}o and Fleur van den Bogert and Qian Tao},
booktitle={Medical Imaging with Deep Learning},
year={2024},
journal={Medical Imaging with Deep Learning},
abstract={Quantitative cardiac $T_1$ mapping by MRI is an essential non-invasive diagnostic tool for cardiomyopathies. Traditionally, deriving the quantitative $T_1$ maps of myocardial tissue involves solving non-linear parametric fitting problems per image voxel, which is slow with sequential CPU computation and requires analytical derivation of the Jacobian matrix per signal model. In this paper, we introduce a new paradigm of parametric fitting, termed ``Torch$T_1$", which leverages the powerful parallelization of modern GPUs and well-established functionalities of auto-differentiation in the deep learning framework of PyTorch. Torch$T_1$ strictly adheres to the signal model and does not require any training. Our method was evaluated on a $T_1$ mapping dataset with both pre-contrast and post-contrast sequences, and benchmarked by conventional CPU-based fitting and recent end-to-end physics-informed neural network (PINN) mapping. Torch$T_1$ showed more accurate and reliable mapping quality compared with the pretrained PINN, with a 13-fold acceleration compared with the CPU baseline. }
pdf={https://openreview.net/forum?id=8ONihf0Fh9},
selected = {true}
}

@article{ao2024anatomycompliant,
title={Anatomy-compliant medical image synthesis by latent diffusion models},
abbr = {MIDL-S},
author={Nuno Miguel Ferreira Capit{\~a}o and Yidong Zhao and Yi Zhang and Nathan Geerts and Jo{\~a}o Viana Lopes and Qian Tao},
booktitle={Medical Imaging with Deep Learning},
journal={Medical Imaging with Deep Learning},
year={2024},
url={https://openreview.net/forum?id=m9pHODd2HS}
}

@article{bozic2024myocardium,
  title={Myocardium Signal Suppression with t2-preparations for Reduced Physiological Noise in Myocardial ASL},
  author={Bozic-Iven, Masa and Zhang, Yi and Tao, Qian and Rapacchi, Stanislas and Schad, Lothar and Weing{\"a}rtner, Sebastian},
  journal={Journal of Cardiovascular Magnetic Resonance},
  volume={26},
  abbr={SCMR-A},
  year={2024},
  publisher={Elsevier}
}

@article{zhao2023relaxometry,
  title={Relaxometry Guided Quantitative Cardiac Magnetic Resonance Image Reconstruction},
  author={Zhao, Yidong and Zhang, Yi and Tao, Qian},
  abbr = {STACOM},
  journal={International Workshop on Statistical Atlases and Computational Models of the Heart},
  pages={349--358},
  year={2023},
  organization={Springer}
}

@article{li2023contrast,
  title={Contrast-Agnostic Groupwise Registration by Robust PCA for Quantitative Cardiac MRI},
  author={Li, Xinqi and Zhang, Yi and Zhao, Yidong and van Gemert, Jan and Tao, Qian},
  abbr = {STACOM},
  journal={International Workshop on Statistical Atlases and Computational Models of the Heart},
  pages={77--87},
  year={2023},
  organization={Springer}
}

@article{liu2023deep,
  title={Deep learning-based cell profiling based on neuronal morphology},
  author={Liu, Qiang and Nicholls, Francesca J and Rowland, Helen A and Dangla-Valls, Adria and Li, Shuhan and Zhang, Yi and Kalinowski, Piotr and Ribe, Elena and Ifkovits, Jamie L and Kumar, Sanjay and others},

  abbr={bioRxiv},
  pages={2023--07},
  year={2023},
  publisher={Cold Spring Harbor Laboratory}
}

@article{Li22,
title	= {The Euclidean Space is Evil: Hyperbolic Attribute Editing for Few-shot Image Generation},
abbr={ICCV},
journal = {Int. Conf. Comput. Vis.},
author	= {Lingxiao Li and Yi Zhang and Shuhui Wang},
year	= {2023},
abstract = {Few-shot image generation is a challenging task since it aims to generate diverse new images for an unseen category with only a few images. Existing methods suffer from the trade-off between the quality and diversity of generated images. To tackle this problem, we propose Hyperbolic Attribute Editing(HAE), a simple yet effective method. Unlike prior arts that work in Euclidean space, HAE captures the hierarchy among images using data from seen categories in hyperbolic space. Given a well-trained HAE, images of unseen categories can be generated by moving the latent code of a given image toward any  meaningful directions in the Poincar√© disk with a fixing radius. Most importantly, the hyperbolic space allows us to control the semantic diversity of the generated images by setting different radii in the disk. Extensive experiments and visualizations demonstrate that HAE is capable of not only generating images with promising quality and diversity using limited data but achieving a highly controllable and interpretable editing process.},
selected = {true},
pdf = {https://arxiv.org/abs/2211.12347}
}

@article{Taylor22,
title	= {Clinical Prompt Learning with Frozen Language Models},
abbr={TNNLS},
author={Niall Taylor* and Yi Zhang* and Dan Joyce and Alejo Nevado-Holgado and Andrey Kormilitzin},
year	= {2022},
abstract = {Prompt learning is a new paradigm in the Natural Language Processing (NLP) field which has shown impressive performance on a number of natural language tasks with common benchmarking text datasets in full, few-shot, and zero-shot train-evaluation setups. Recently, it has even been observed that large but frozen pre-trained language models (PLMs) with prompt learning outperform smaller but fine-tuned models. However, as with many recent NLP trends, the performance of even the largest PLMs such as GPT-3 do not perform well on specialized domains (e.g. medical text), and the common practice to achieve State of the Art (SoTA) results still consists of pre-training and fine-tuning the PLMs on downstream tasks. The reliance on fine-tuning large PLMs is problematic in clinical settings where data is often held in non-GPU environments, and more resource efficient methods of training specialized domain models is crucial. We investigated the viability of prompt learning on clinically meaningful decision tasks and directly compared with more traditional fine-tuning methods. Results are partially in line with the prompt learning literature, with prompt learning able to match or improve on traditional fine-tuning with substantially fewer trainable parameters and requiring less training data. We argue that prompt learning therefore provides lower computational resource costs applicable to clinical settings, that can serve as an alternative to fine-tuning ever increasing in size PLMs.},
journal	= {IEEE Trans. Neural Netw. Learn. Syst.},
selected = {true},
pdf = {https://arxiv.org/abs/2205.05535}
}



